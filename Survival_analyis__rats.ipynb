{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "023ea80a",
   "metadata": {
    "id": "023ea80a"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split,cross_val_score,KFold,StratifiedKFold\n",
    "import torchtuples as tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e38f06fc",
   "metadata": {
    "id": "e38f06fc"
   },
   "outputs": [],
   "source": [
    "from sksurv.linear_model import CoxPHSurvivalAnalysis, CoxnetSurvivalAnalysis\n",
    "from sksurv.preprocessing import OneHotEncoder, encode_categorical\n",
    "\n",
    "from sklearn import set_config\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4bc81497",
   "metadata": {
    "id": "4bc81497",
    "outputId": "7091c35d-629c-455a-cd68-228fa057cf7c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>litter</th>\n",
       "      <th>rx</th>\n",
       "      <th>time</th>\n",
       "      <th>status</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>104</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>91</td>\n",
       "      <td>0</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>104</td>\n",
       "      <td>0</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>104</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>79</td>\n",
       "      <td>1</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>104</td>\n",
       "      <td>0</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     litter  rx  time  status sex\n",
       "0         1   1   101       0   f\n",
       "1         1   0    49       1   f\n",
       "2         1   0   104       0   f\n",
       "3         2   1    91       0   m\n",
       "4         2   0   104       0   m\n",
       "..      ...  ..   ...     ...  ..\n",
       "295      99   0   104       0   f\n",
       "296      99   0    79       1   f\n",
       "297     100   1    92       0   m\n",
       "298     100   0   104       0   m\n",
       "299     100   0   102       0   m\n",
       "\n",
       "[300 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datas = pd.read_csv('rats.csv')\n",
    "datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a20ae016",
   "metadata": {
    "id": "a20ae016"
   },
   "outputs": [],
   "source": [
    "data_y = datas.loc[:, ['time', 'status']].copy()\n",
    "data_y = data_y.rename(columns={'status': 'cens'})\n",
    "data_x = datas.drop(['time', 'status'], axis=1)\n",
    "\n",
    "data_x['sex'] = data_x['sex'].astype('category')\n",
    "data_x = OneHotEncoder().fit_transform(data_x)\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_x, data_y, test_size=0.3, random_state=1)\n",
    "list_of_tuples = list(y_train.itertuples(index=False, name=None))\n",
    "swapped_list = [(t[1], t[0]) for t in list_of_tuples]\n",
    "y_train = np.array(swapped_list, dtype=[('cens', bool), ('time', float)])\n",
    "list_of_tuples = list(y_test.itertuples(index=False, name=None))\n",
    "swapped_list = [(t[1], t[0]) for t in list_of_tuples]\n",
    "y_test = np.array(swapped_list, dtype=[('cens', bool), ('time', float)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6715b7b9",
   "metadata": {
    "id": "6715b7b9"
   },
   "outputs": [],
   "source": [
    "for df in [X_train, X_test]:\n",
    "    numeric_columns = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "    df[numeric_columns] = (df[numeric_columns] - df[numeric_columns].min()) / (df[numeric_columns].max() - df[numeric_columns].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f05796d6",
   "metadata": {
    "id": "f05796d6",
    "outputId": "0a499322-6300-468d-b871-9089909f6258"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([(False, 104.), (False,  97.), (False, 104.), (False,  72.),\n",
       "       ( True,  79.), ( True,  86.), (False, 104.), (False,  89.),\n",
       "       (False, 104.), (False, 104.), (False,  98.), (False,  99.),\n",
       "       (False,  69.), (False,  79.), (False,  87.), ( True,  73.),\n",
       "       (False, 104.), (False,  92.), (False,  95.), (False, 104.),\n",
       "       (False, 102.), (False,  74.), (False, 104.), ( True,  96.),\n",
       "       (False,  91.), (False, 104.), (False, 104.), (False,  76.),\n",
       "       ( True,  55.), (False,  82.), (False,  91.), (False, 104.),\n",
       "       (False, 104.), (False,  96.), (False, 104.), (False, 104.),\n",
       "       (False,  91.), ( True,  45.), (False, 104.), ( True, 101.),\n",
       "       (False, 104.), (False,  91.), (False, 104.), ( True,  84.),\n",
       "       (False, 104.), (False, 104.), (False,  85.), (False, 104.),\n",
       "       (False, 104.), (False, 104.), (False,  91.), (False,  95.),\n",
       "       (False, 104.), (False, 102.), (False,  78.), (False,  89.),\n",
       "       (False, 103.), ( True,  40.), (False,  83.), ( True,  68.),\n",
       "       (False, 104.), (False, 104.), ( True,  78.), (False, 104.),\n",
       "       (False, 104.), (False,  77.), (False,  91.), (False, 104.),\n",
       "       (False, 102.), (False,  93.), (False, 104.), ( True,  67.),\n",
       "       (False,  83.), (False,  54.), (False,  98.), (False, 104.),\n",
       "       (False, 104.), (False, 104.), (False,  73.), ( True,  70.),\n",
       "       (False,  81.), (False, 102.), (False,  80.), ( True, 102.),\n",
       "       (False, 104.), (False, 104.), (False,  32.), (False,  63.),\n",
       "       (False,  49.), (False, 104.), ( True, 103.), ( True,  89.),\n",
       "       (False, 100.), (False, 104.), (False,  94.), (False, 104.),\n",
       "       (False, 104.), (False, 102.), (False,  69.), (False,  65.),\n",
       "       (False,  89.), (False, 102.), ( True,  80.), (False, 104.),\n",
       "       (False, 104.), ( True,  72.), (False,  61.), (False, 104.),\n",
       "       (False, 104.), ( True, 104.), (False,  82.), (False,  79.),\n",
       "       (False,  94.), ( True,  94.), (False, 104.), (False,  73.),\n",
       "       (False, 104.), (False, 104.), (False, 104.), (False,  94.),\n",
       "       (False,  87.), (False, 104.), ( True,  80.), (False, 104.),\n",
       "       (False, 104.), (False,  79.), (False, 104.), (False, 104.),\n",
       "       (False, 102.), (False,  80.), (False,  92.), (False,  23.),\n",
       "       (False, 104.), (False,  77.), (False,  91.), (False,  88.),\n",
       "       ( True,  71.), ( True,  50.), (False, 104.), (False, 104.),\n",
       "       (False,  54.), (False,  86.), (False, 102.), (False, 102.),\n",
       "       (False, 104.), (False, 104.), (False, 104.), (False,  98.),\n",
       "       (False, 104.), (False,  91.), (False, 104.), (False,  90.),\n",
       "       (False, 102.), (False, 104.), (False,  89.), (False,  76.),\n",
       "       (False, 104.), (False, 104.), (False,  87.), (False,  91.),\n",
       "       (False, 102.), (False,  74.), (False, 104.), (False, 104.),\n",
       "       (False, 104.), (False,  91.), (False,  94.), (False, 104.),\n",
       "       (False,  51.), (False,  80.), (False,  98.), (False, 104.),\n",
       "       (False, 104.), (False,  53.), (False, 104.), (False,  91.),\n",
       "       (False,  77.), (False, 104.), ( True,  88.), (False, 104.),\n",
       "       (False, 104.), (False, 104.), (False, 104.), (False,  55.),\n",
       "       (False,  96.), ( True,  49.), (False,  98.), (False, 102.),\n",
       "       (False, 104.), (False, 103.), (False,  95.), (False,  94.),\n",
       "       (False,  92.), (False, 104.), (False,  78.), ( True,  92.),\n",
       "       ( True, 102.), ( True,  89.), (False, 104.), (False,  77.),\n",
       "       (False,  51.), (False, 101.), (False,  63.), (False, 104.),\n",
       "       (False,  83.), (False, 102.), (False,  67.), ( True,  39.),\n",
       "       ( True,  81.), (False,  94.)],\n",
       "      dtype=[('cens', '?'), ('time', '<f8')])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640776f0",
   "metadata": {
    "id": "640776f0"
   },
   "source": [
    "# MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ac3d411",
   "metadata": {
    "id": "8ac3d411",
    "outputId": "ca008a46-e725-438c-ebbe-d3f78a94a34d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7519181585677749"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cox_lasso = CoxnetSurvivalAnalysis(l1_ratio=1, alpha_min_ratio=0.01)\n",
    "cox_lasso.fit(X_train, y_train)\n",
    "cox_lasso.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92b5c88a",
   "metadata": {
    "id": "92b5c88a",
    "outputId": "c821be79-572d-4dcd-ced7-c1e5f825edc8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.731457800511509"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cox_ridge = CoxnetSurvivalAnalysis(l1_ratio=0.00001, alpha_min_ratio=0.01)\n",
    "cox_ridge.fit(X_train, y_train)\n",
    "cox_ridge.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d8423c2",
   "metadata": {
    "id": "4d8423c2"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "import torch # For building the networks\n",
    "import torchtuples as tt # Some useful functions\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from pycox.datasets import support\n",
    "from pycox.models import DeepHitSingle\n",
    "from pycox.models import CoxPH\n",
    "from pycox.evaluation import EvalSurv\n",
    "from pycox.preprocessing.feature_transforms import OrderedCategoricalLong\n",
    "from pycox.models.loss import rank_loss_deephit_single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "16b53b90",
   "metadata": {
    "id": "16b53b90"
   },
   "outputs": [],
   "source": [
    "data_y_transform_train = pd.DataFrame.from_records(y_train, columns=['event', 'time'])\n",
    "data_y_transform_test = pd.DataFrame.from_records(y_test, columns=['event', 'time'])\n",
    "data_y_transform_train['cens'] = data_y_transform_train['cens'].replace({True: 1, False: 0})\n",
    "data_y_transform_test['cens'] = data_y_transform_test['cens'].replace({True: 1, False: 0})\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train_values= X_train.values\n",
    "X_test_values= X_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1c54b7e1",
   "metadata": {
    "id": "1c54b7e1"
   },
   "outputs": [],
   "source": [
    "num_durations = 10\n",
    "\n",
    "labtrans = DeepHitSingle.label_transform(num_durations)\n",
    "get_target = lambda df: (df['time'].values, df['cens'].values)\n",
    "y_train_deephit = labtrans.fit_transform(*get_target(data_y_transform_train))\n",
    "durations_test, events_test = get_target(data_y_transform_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ab12cd52",
   "metadata": {
    "id": "ab12cd52",
    "outputId": "a9bebdb7-82a0-433e-aa20-7409a2c4d4f1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\torchtuples\\callbacks.py:607: UserWarning: This overload of add is deprecated:\n",
      "\tadd(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd(Tensor other, *, Number alpha) (Triggered internally at  ..\\torch\\csrc\\utils\\python_arg_parser.cpp:1025.)\n",
      "  p.data = p.data.add(-weight_decay * eta, p.data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\t[0s / 0s],\t\ttrain_loss: 0.5115\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 0.5065\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 0.4840\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 0.4533\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 0.4573\n",
      "5:\t[0s / 1s],\t\ttrain_loss: 0.4328\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 0.4453\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 0.4381\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 0.4174\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 0.4189\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 0.4057\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 0.4162\n",
      "12:\t[0s / 1s],\t\ttrain_loss: 0.4242\n",
      "13:\t[0s / 1s],\t\ttrain_loss: 0.4115\n",
      "14:\t[0s / 1s],\t\ttrain_loss: 0.4116\n",
      "15:\t[0s / 1s],\t\ttrain_loss: 0.4154\n",
      "16:\t[0s / 2s],\t\ttrain_loss: 0.4016\n",
      "17:\t[0s / 2s],\t\ttrain_loss: 0.4122\n",
      "18:\t[0s / 2s],\t\ttrain_loss: 0.4092\n",
      "19:\t[0s / 2s],\t\ttrain_loss: 0.3880\n",
      "20:\t[0s / 2s],\t\ttrain_loss: 0.4154\n",
      "21:\t[0s / 2s],\t\ttrain_loss: 0.3799\n",
      "22:\t[0s / 2s],\t\ttrain_loss: 0.3963\n",
      "23:\t[0s / 2s],\t\ttrain_loss: 0.3760\n",
      "24:\t[0s / 2s],\t\ttrain_loss: 0.3961\n",
      "25:\t[0s / 2s],\t\ttrain_loss: 0.3870\n",
      "26:\t[0s / 2s],\t\ttrain_loss: 0.3741\n",
      "27:\t[0s / 3s],\t\ttrain_loss: 0.3754\n",
      "28:\t[0s / 3s],\t\ttrain_loss: 0.4102\n",
      "29:\t[0s / 3s],\t\ttrain_loss: 0.3750\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.717391304347826"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_features = X_train.shape[1]\n",
    "out_features = labtrans.out_features\n",
    "num_nodes = [32]\n",
    "batch_norm = True\n",
    "dropout = 0.2\n",
    "\n",
    "net = tt.practical.MLPVanilla(in_features, num_nodes, out_features, batch_norm, dropout)\n",
    "optimizer = tt.optim.AdamWR(decoupled_weight_decay=0.01, cycle_eta_multiplier=0.8,\n",
    "                            cycle_multiplier=2)\n",
    "model_deep_hit = DeepHitSingle(net, optimizer, alpha = 0.2, sigma = 0.1, duration_index=labtrans.cuts)\n",
    "epochs = 30\n",
    "batch_size=8\n",
    "model_deep_hit.fit(X_train_values, y_train_deephit, batch_size, epochs)\n",
    "surv = model_deep_hit.predict_surv_df(X_test_values)\n",
    "ev = EvalSurv(surv, durations_test, events_test, censor_surv='km')\n",
    "ev.concordance_td('antolini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "08218960",
   "metadata": {
    "id": "08218960",
    "outputId": "78858407-27a7-43fb-8d5b-178780cb736d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7621483375959079"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sksurv.ensemble import RandomSurvivalForest\n",
    "rsf = RandomSurvivalForest(n_estimators=1000,\n",
    "                           min_samples_split=10,\n",
    "                           min_samples_leaf=15,\n",
    "                           n_jobs=-1,\n",
    "                           random_state=42)\n",
    "rsf.fit(X_train,y_train)\n",
    "rsf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dda38a30",
   "metadata": {
    "id": "dda38a30",
    "outputId": "c3cd8e0d-9376-43dd-cdb1-7b4e067d98a3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7519181585677749"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sksurv.linear_model import CoxPHSurvivalAnalysis\n",
    "estimator = CoxPHSurvivalAnalysis().fit(X_train, y_train)\n",
    "estimator.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d3fd4e90",
   "metadata": {
    "id": "d3fd4e90",
    "outputId": "ebe69a6c-d591-4314-c30f-538aca2f9bd5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7519181585677749"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sksurv.linear_model import CoxnetSurvivalAnalysis\n",
    "estimator = CoxnetSurvivalAnalysis(l1_ratio=0.99, fit_baseline_model=True)\n",
    "estimator.fit(X_train, y_train)\n",
    "estimator.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ad353d",
   "metadata": {
    "id": "34ad353d",
    "outputId": "9c3bff5c-b166-4639-b5c5-bee3d6d4fe1c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7477876106194691"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sksurv.ensemble import GradientBoostingSurvivalAnalysis\n",
    "est_cph_tree = GradientBoostingSurvivalAnalysis(\n",
    "    n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0\n",
    ")\n",
    "est_cph_tree.fit(X_train, y_train)\n",
    "cindex = est_cph_tree.score(X_test, y_test)\n",
    "cindex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2669ea09",
   "metadata": {
    "id": "2669ea09"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e255fc",
   "metadata": {
    "id": "39e255fc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e2e147ae",
   "metadata": {
    "id": "e2e147ae"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchtuples as tt\n",
    "\n",
    "from pycox.datasets import metabric\n",
    "from pycox.models import CoxPH\n",
    "from pycox.evaluation import EvalSurv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3ff3ed0c",
   "metadata": {
    "id": "3ff3ed0c"
   },
   "outputs": [],
   "source": [
    "get_target = lambda df: (df['time'].values, df['cens'].values)\n",
    "y_train_deepsurv = get_target(data_y_transform_train)\n",
    "durations_test, events_test = get_target(data_y_transform_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "06b73e8d",
   "metadata": {
    "id": "06b73e8d"
   },
   "outputs": [],
   "source": [
    "in_features = X_train.shape[1]\n",
    "num_nodes = [64, 64]\n",
    "out_features = 1\n",
    "batch_norm = True\n",
    "dropout = 0.2\n",
    "output_bias = False\n",
    "\n",
    "net = tt.practical.MLPVanilla(in_features, num_nodes, out_features, batch_norm,\n",
    "                              dropout, output_bias=output_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "159992a3",
   "metadata": {
    "id": "159992a3",
    "outputId": "6ea8aa2e-ba86-4fbf-f6a4-431397f22ca8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\t[0s / 0s],\t\n",
      "1:\t[0s / 0s],\t\n",
      "2:\t[0s / 0s],\t\n",
      "3:\t[0s / 0s],\t\n",
      "4:\t[0s / 1s],\t\n",
      "5:\t[0s / 1s],\t\n",
      "6:\t[0s / 1s],\t\n",
      "7:\t[0s / 1s],\t\n",
      "8:\t[0s / 1s],\t\n",
      "9:\t[0s / 1s],\t\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6820480404551201"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = tt.optim.AdamWR(decoupled_weight_decay=0.01, cycle_eta_multiplier=0.8,\n",
    "                            cycle_multiplier=2)\n",
    "model_deepsurv = CoxPH(net, optimizer)\n",
    "batch_size= 4\n",
    "epochs= 100\n",
    "verbose=1\n",
    "callbacks = [tt.callbacks.EarlyStopping()]\n",
    "log = model_deepsurv.fit(X_train_values, y_train_deepsurv, batch_size, epochs, callbacks, verbose)\n",
    "model_deepsurv.compute_baseline_hazards()\n",
    "surv = model_deepsurv.predict_surv_df(X_test_values)\n",
    "ev = EvalSurv(surv, durations_test, events_test, censor_surv='km')\n",
    "ev.concordance_td()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "46e853af",
   "metadata": {
    "id": "46e853af"
   },
   "outputs": [],
   "source": [
    "from pycox.models import LogisticHazard\n",
    "# from pycox.models import PMF\n",
    "# from pycox.models import DeepHitSingle\n",
    "from pycox.evaluation import EvalSurv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d45c06c0",
   "metadata": {
    "id": "d45c06c0"
   },
   "outputs": [],
   "source": [
    "num_durations = 10\n",
    "\n",
    "labtrans = LogisticHazard.label_transform(num_durations)\n",
    "# labtrans = PMF.label_transform(num_durations)\n",
    "# labtrans = DeepHitSingle.label_transform(num_durations)\n",
    "\n",
    "get_target = lambda df: (df['time'].values, df['cens'].values)\n",
    "y_train_loghazard = labtrans.fit_transform(*get_target(data_y_transform_train))\n",
    "y_test_loghazard = labtrans.transform(*get_target(data_y_transform_test))\n",
    "\n",
    "\n",
    "# # We don't need to transform the test labels\n",
    "durations_test, events_test = get_target(data_y_transform_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c517150a",
   "metadata": {
    "id": "c517150a"
   },
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train_values= X_train.values\n",
    "X_test_values= X_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "29cae88b",
   "metadata": {
    "id": "29cae88b",
    "outputId": "93c66687-983b-4bde-9f60-b07c4bde3e5f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\t[0s / 0s],\t\ttrain_loss: 5.7757\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 5.0907\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.0231\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 2.6277\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 1.5295\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 0.8301\n",
      "6:\t[0s / 0s],\t\ttrain_loss: 0.6154\n",
      "7:\t[0s / 0s],\t\ttrain_loss: 0.5652\n",
      "8:\t[0s / 0s],\t\ttrain_loss: 0.5368\n",
      "9:\t[0s / 0s],\t\ttrain_loss: 0.4975\n",
      "10:\t[0s / 0s],\t\ttrain_loss: 0.5137\n",
      "11:\t[0s / 0s],\t\ttrain_loss: 0.4775\n",
      "12:\t[0s / 0s],\t\ttrain_loss: 0.4842\n",
      "13:\t[0s / 0s],\t\ttrain_loss: 0.5114\n",
      "14:\t[0s / 0s],\t\ttrain_loss: 0.5214\n",
      "15:\t[0s / 0s],\t\ttrain_loss: 0.5024\n",
      "16:\t[0s / 0s],\t\ttrain_loss: 0.4960\n",
      "17:\t[0s / 0s],\t\ttrain_loss: 0.4970\n",
      "18:\t[0s / 0s],\t\ttrain_loss: 0.4446\n",
      "19:\t[0s / 0s],\t\ttrain_loss: 0.4918\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7583120204603581"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_features = X_train.shape[1]\n",
    "num_nodes = [32, 32]\n",
    "out_features = labtrans.out_features\n",
    "batch_norm = True\n",
    "dropout = 0.1\n",
    "net = tt.practical.MLPVanilla(in_features, num_nodes, out_features, batch_norm, dropout)\n",
    "model = LogisticHazard(net, tt.optim.Adam(0.01), duration_index=labtrans.cuts)\n",
    "batch_size = 32\n",
    "epochs = 20\n",
    "log= model.fit(X_train_values, y_train_loghazard, batch_size, epochs)\n",
    "surv = model.predict_surv_df(X_test_values)\n",
    "ev = EvalSurv(surv, durations_test, events_test, censor_surv='km')\n",
    "ev.concordance_td('antolini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9fb6f9ab",
   "metadata": {
    "id": "9fb6f9ab",
    "outputId": "60cf9698-56d3-4e00-96da-2fc7b8472e25"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concordance Index: 0.7468030690537084\n"
     ]
    }
   ],
   "source": [
    "cox= CoxnetSurvivalAnalysis()\n",
    "rsf = RandomSurvivalForest(n_estimators=1000,\n",
    "                           min_samples_split=10,\n",
    "                           min_samples_leaf=15,\n",
    "                           random_state=42)\n",
    "cox.fit(X_train_values, y_train)\n",
    "rsf.fit(X_train_values, y_train)\n",
    "cox_pred = cox.predict(X_test_values)\n",
    "rsf_pred = rsf.predict(X_test_values)\n",
    "ensemble_pred= (cox_pred+rsf_pred)/2\n",
    "from sksurv.metrics import concordance_index_censored\n",
    "cindex = concordance_index_censored(y_test[\"cens\"], y_test[\"time\"], ensemble_pred)\n",
    "print(\"Concordance Index:\", cindex[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1eec45dc",
   "metadata": {
    "id": "1eec45dc",
    "outputId": "605bd202-9980-48ed-f4d9-cd6b7262a96c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concordance Index: 0.7621483375959079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but CoxnetSurvivalAnalysis was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "cox= CoxPHSurvivalAnalysis()\n",
    "rsf = RandomSurvivalForest(n_estimators=1000,\n",
    "                           min_samples_split=10,\n",
    "                           min_samples_leaf=15,\n",
    "                           random_state=42)\n",
    "cox_lasso = CoxnetSurvivalAnalysis(l1_ratio=1, alpha_min_ratio=0.01)\n",
    "cox_lasso.fit(X_train, y_train)\n",
    "cox.fit(X_train_values, y_train)\n",
    "rsf.fit(X_train_values, y_train)\n",
    "lasso_predict = cox_lasso.predict(X_test_values)\n",
    "cox_pred = cox.predict(X_test_values)\n",
    "rsf_pred = rsf.predict(X_test_values)\n",
    "ensemble_pred = np.maximum(cox_pred, rsf_pred, lasso_predict)\n",
    "from sksurv.metrics import concordance_index_censored\n",
    "cindex = concordance_index_censored(y_test[\"cens\"], y_test[\"time\"], ensemble_pred)\n",
    "print(\"Concordance Index:\", cindex[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cfb80b1",
   "metadata": {
    "id": "7cfb80b1"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
